{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhangc/miniconda3/envs/metal/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import scipy.optimize\n",
    "\n",
    "np_rng = np.random.default_rng()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bi-quadratic optimization problem\n",
    "\n",
    "Given a $16\\times 16\\times 16\\times 16$ tensor (or say 4-dimensional array) $B$, we want to find the minimum value of the following function\n",
    "\n",
    "$$\\min_{x,y} \\sum_{ijkl} x_iy_jB_{ijkl}x_ky_l$$\n",
    "\n",
    "where $x,y$ are united vector in real space\n",
    "\n",
    "$$x,y\\in\\mathbb{R}^{16},||x||_2=||y||_2=1$$\n",
    "\n",
    "The `hf_loss_function()/hf_loss_function_with_grad()` below just implement the above function.\n",
    "\n",
    "## bi-quadratic优化问题\n",
    "\n",
    "给定一个 $16\\times 16\\times 16\\times 16$ 张量 (或者说四维数组) $B$, 目标是找到下面这个函数的最小值\n",
    "\n",
    "$$\\min_{x,y} \\sum_{ijkl} x_iy_jB_{ijkl}x_ky_l$$\n",
    "\n",
    "其中 $x,y$ 是实数域上的16维的单位长度矢量\n",
    "\n",
    "$$x,y\\in\\mathbb{R}^{16},||x||_2=||y||_2=1$$\n",
    "\n",
    "下方的 `hf_loss_function()/hf_loss_function_with_grad()` 正是实现了这个函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hf_loss_function(vecX, vecY, matB):\n",
    "    dimX = vecX.shape[0]\n",
    "    dimY = vecY.shape[0]\n",
    "    vecX = vecX / np.linalg.norm(vecX)\n",
    "    vecY = vecY / np.linalg.norm(vecY)\n",
    "    ret = np.einsum(matB, [0,1,2,3], vecX, [0], vecY, [1], vecX, [2], vecY, [3], [], optimize=True)\n",
    "    return ret\n",
    "\n",
    "\n",
    "def hf_loss_function_with_grad(vecXY, matB):\n",
    "    # same function but with gradient (useful for optimization)\n",
    "    torchX = torch.tensor(vecXY[:16], dtype=torch.float64, requires_grad=True)\n",
    "    torchY = torch.tensor(vecXY[16:], dtype=torch.float64, requires_grad=True)\n",
    "    torchB = torch.tensor(matB, dtype=torch.float64)\n",
    "    tmp0 = torchX / torch.linalg.norm(torchX)\n",
    "    tmp1 = torchY / torch.linalg.norm(torchY)\n",
    "    fval = torch.einsum(torchB, [0,1,2,3], tmp0, [0], tmp1, [1], tmp0, [2], tmp1, [3], [])\n",
    "    fval.backward()\n",
    "    grad = np.concatenate([torchX.grad.detach().numpy(), torchY.grad.detach().numpy()])\n",
    "    return fval.item(), grad\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually, we already know its optimal points\n",
    "\n",
    "$$x_1=x_6=x_{11}=x_{16}=\\frac{1}{2}$$\n",
    "\n",
    "$$y_1=-y_6=y_{11}=-y_{16}=\\frac{1}{2}$$\n",
    "\n",
    "实际上，我们知道这个问题的解析解\n",
    "\n",
    "$$x_1=x_6=x_{11}=x_{16}=\\frac{1}{2}$$\n",
    "\n",
    "$$y_1=-y_6=y_{11}=-y_{16}=\\frac{1}{2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum: -7.703719777548943e-34\n",
      "minimum: -7.703719777548943e-34\n"
     ]
    }
   ],
   "source": [
    "matB = np.load('biquadratic_mat.npy') #(np,float64,(16,16,16,16))\n",
    "\n",
    "Xstar = np.eye(4).reshape(-1)/2\n",
    "Ystar = np.diag([1,-1,1,-1]).reshape(-1)/2\n",
    "print('minimum:', hf_loss_function(Xstar, Ystar, matB))\n",
    "print('minimum:', hf_loss_function(Ystar, Xstar, matB)) #inter-changable"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But if we pretend we don't know the answer and want to find it using optimization, we always fail.\n",
    "\n",
    "但如果我们假装不知道答案，而是尝试通过优化算法来寻找解，那几乎总会失败"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial loss: 1.0074233556485386\n",
      "converged loss: 0.008879706450784923\n"
     ]
    }
   ],
   "source": [
    "Xtest = np_rng.normal(size=16)\n",
    "Ytest = np_rng.normal(size=16)\n",
    "print('initial loss:', hf_loss_function(Xtest, Ytest, matB))\n",
    "\n",
    "theta0 = np.concatenate([Xtest,Ytest])\n",
    "theta_optim = scipy.optimize.minimize(hf_loss_function_with_grad, theta0, args=matB, method='L-BFGS-B', jac=True, tol=1e-10)\n",
    "print('converged loss:', theta_optim.fun) #almost always never be 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the challenge, could you provide a method to find this optimal point.\n",
    "\n",
    "挑战：对于这个优化问题，你能否提出一个也许可行的解决方案呢"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "metal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1da8b4f11a989d44d193420904ada205490cc10fbe57ce1c49024a27ca8cfdd1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
